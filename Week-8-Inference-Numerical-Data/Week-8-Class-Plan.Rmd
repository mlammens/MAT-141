---
title: "Week 8 - Wed - Class Plan - Hypothesis Testing"
author: "Matthew Aiello-Lammens"
date: "10/27/2021"
output:
  html_document:
    toc: yes
---

# Learning Objectives

* Compare and contrast Confidence Intervals and Hypothesis Tests
* Apply a hypothesis test on normally distributed (or assumed normally distributed) data
* Simulate the effects of setting your Type I error rate (i.e., $\alpha$) value equal to 0.05

# Complete Monday Lecture

[Hypothesis testing lecture](https://docs.google.com/presentation/d/1KyEPsVpfnhfuFg2ee_P8hgrLO-WB1_xUBXqEemdt-uA/edit?usp=sharing)

# Worked example on 1-sample hypothesis test

## *More* work with the Youth Risk Behavior Surveillance System (YRBSS) data

This week, we are again going to use the Youth Risk Behavior Surveillance System (YRBSS) data set.
Let's begin by loading the data into our environment.

```{r}
library(openintro)
data(yrbss)
```

Next, draw a random sample of these data, with sample size equal to 100.

```{r}
set.seed(1981)
yrbss_samp = yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 100), ]
```


## Confidence Intervals

Calculate the **sample mean** and the **95% Confidence Interval** for **height** based on your sample. Recall that the **Confidence Interval** is:

$$
\bar{x} \pm 1.96\times SE \\
$$

or, otherwise written as:

$$
\bar{x} \pm 1.96\times \frac{s}{\sqrt{n}}
$$


```{r}
mean(yrbss_samp$height, na.rm = TRUE)

mean(yrbss_samp$height, na.rm = TRUE) + 1.96*(sd(yrbss_samp$height, na.rm = TRUE)/sqrt(100))
mean(yrbss_samp$height, na.rm = TRUE) - 1.96*(sd(yrbss_samp$height, na.rm = TRUE)/sqrt(100))

```

## Compare to population mean

Calculate the **population mean** for **height** for the `yrbss` data set. 
Does our **95% confidence interval** calculated in above *include* the true population mean?


```{r}
mean(yrbss$height, na.rm = TRUE)
```

> In my case, my 95% **DOES** include the population mean. For the most part, we should expect this to be the case, though we could get a set of data in our sample that happens to be extreme, and therefore, the CI does not include the mean.


## Z-stat

Using the **population mean** calculated above, and the sample mean calculated even further above, calculate the $z$ statistic associated with your sample mean. Is your sample mean significantly different from the population mean?


```{r}
# Get the sample mean (again)
yrbss_samp_mean = mean(yrbss_samp$height, na.rm = TRUE)

# Get the population mean (again)
yrbss_pop_mean = mean(yrbss$height, na.rm = TRUE)

# Get the Standard Error of the Mean for the sample (again)
yrbss_samp_SE = sd(yrbss_samp$height, na.rm = TRUE)/sqrt(100)

## Calcualte the Z statistic
z_stat = (yrbss_samp_mean - yrbss_pop_mean) / yrbss_samp_SE
print("my z_stat value")
z_stat

## Calculate the probability of this Z-stat - assume a **TWO TAILED** test
## Below, I'm using the absolute value of the z_stat value, then
## looking at the upper tail only.
print("probability of my z_stat value, assuming two-tailed test")
2 * pnorm(abs(z_stat), lower.tail = FALSE)

```


> Looking at the probability value for my Z-stat value, assuming an $\alpha = 0.05$ significane value, we DO NOT reject the null hypothesis. Thus, we support, but do not prove, the hypothesis that my sample mean is NOT significantly different than the population mean.


Let's repeat this process 100 times. 

```{r}
p_vals = c()

# start a for loop the does 100 iterations
for(x in 1:100){
  # get a sample of the data of size 100
  yrbss_samp = yrbss[sample(x = 1:nrow(yrbss), replace = FALSE, size = 100), ]
  
  # calculate the new sample mean
  yrbss_samp_mean = mean(yrbss_samp$height, na.rm = TRUE)

  # calculate the new SE
  yrbss_samp_SE = sd(yrbss_samp$height, na.rm = TRUE)/sqrt(nrow(yrbss_samp))

  # calcualte the Z statistic
  z_stat = (yrbss_samp_mean - yrbss_pop_mean) / yrbss_samp_SE
  
  # calculate the p-value
  p_val = 2 * pnorm(abs(z_stat), lower.tail = FALSE)
  
  # add this p-val to the list
  p_vals = c(p_vals, p_val)
}

```

How many of the sampled data sets are significantly different from the population mean?

```{r}
sum(p_vals < 0.05)
```

That's pretty close to a 5% type I error rate!

